/*
========================================================================================
    nf-core/eqtl Nextflow base config file
========================================================================================
    A 'blank slate' config file, appropriate for general use on most high performance
    compute environments. Assumes that all software is installed and available on
    the PATH. Runs in `local` mode - all jobs will be run on the logged in environment.
----------------------------------------------------------------------------------------
*/
params{
    chunkSize=20 // For SAIGE and LIMIX how many genes to chunk at a time to run on a single computation node.

    LIMIX{
        run=false
        callRate=0.95
        blockSize=1500
        hwe=0.0000001
    }

    SAIGE{
        run=true
        nr_expression_pcs=5
        // chromosomes_to_test=[1,2,3,4,5,6,7,8,9,10.11,12,13,14,15,16,17,18,19,20,21,X]
        chromosomes_to_test=[1,2] 
        q_val_threshold_for_conditioning=0.05 // if there are more than 1 value with a qvalue lover than this for gene then we send it in for conditioning rounds.
        minMAF=0.05
        minMAC=20
        SPAcutoff=2
        markers_per_chunk=10000
        covariate_obs_columns='' // What andata.obs to use as covariates in SAIGE
        cis_trans_mode = 'cis' // cis|trans -- whether to run in cis or trans mode. If running in cis mode pipeline will use window size to test for associations in the +- surounding window of the TSS.
    }

    TensorQTL{
        run=true
        optimise_pcs = true
        interaction_file='' // to run interaction, provide a TSV with genotype ID and interaction 
        interaction_maf = 0.1 // what interaction MAF to use in tensorqtl interactions test
        interaction_pc_cor_threshold = 0.25 // Drop PCs correlated with interaction above this threshold. Use 1 if you don not want to drop PCs
        trans_by_cis=true // Run trans-by-cis analysis (all genes, limiting variants) following OPTIM PCs?
        trans_of_cis=true // Run trans-of-cis eQTL analysis (all variants, limiting genes), following OPTIM PCs?
        trans_by_cis_pval_threshold = 0.01
        alpha=0.05
    }

    covariates{
        nr_phenotype_pcs = '2,4' // this is used for Tensorqtl
        nr_genotype_pcs = 4
        extra_covariates_file = ''
    }

    genotypes{
        subset_genotypes_to_available=false // if true, then the expression data will be first processed and then the samples availbale in all the expression data will be subset from genotype files
        apply_bcftools_filters=true // if true and vcf file is provided then preprocessing will be done on the files. Whether we want to perform the folowing filters as per bcftools_filters
        use_gt_dosage = true // whether to use dosage. This will convert the vcf/bed to pgen
        preprocessed_bed_file='' //if user already has a bed file then this can be used instead of vcf file, and it will avoid the conversion, this can also be taken from the results/genotypes/plink_genotypes_bed 
        preprocessed_pgen_file='' //if user already has a pgen file then this can be used instead of vcf file, and it will avoid the conversion, this can also be taken from the results/genotypes/plink_genotypes_pgen
    }

    outdir='results' // where to output results
    copy_mode = "rellink" // method of processing files in work dir.
    split_aggregation_adata=false  // Should we split the andata per condition before proceeding with the agregations and normalisations
    genotype_phenotype_mapping_file='' // bridging file between genotype ids and phenotype ids referenced in the sample_column
    aggregation_columns='Azimuth:predicted.celltype.l1' //for the scrna h5ad file define which annotations to use when aggregating the data. Can be one value or multiple comma separated values
    aggregation_subentry='Mono' // 'Mono,B,DC' If provided only these subcolumns that are contained within the aggregation_columns entry will be analysed.
    sample_column='Pool.Donor' // for the scrna h5ad defines which column has the sample name (can be identical to gt_id_column if sample=individual)
    utilise_gpu = false // whether to use gpu in tensorqtl or not. 
    gtf_type='gene' //# 'gene|transcript' - if we are using default gtf file as an input we need to know if we are looking at the transcripts of genes. used when gtf file is read to select necessary genes.
    input_tables_column_delimiter = '\t' // by default pipeline takes tsv files but csv could be provided too if this is changed.
    n_min_cells = '5' // The number of min cells for individual to select it for use in qtl mapping. 
    n_min_individ = '30' //Number of individuals that has this particular celltype or aggregation column. Do not select less than 25 since this may result in a permutation issue with tensorqtl
    aggregation_method = 'dMean,dSum' // can be: dMean|dSum or both dMean,dSum separated by comma
    inverse_normal_transform = 'FALSE' // Inverse normal trasnform data as part of normalisation
    bcftools_filters = '--max-alleles 2 -m2 -M2 -v snps' // Filters to apply to input vcf file if genotypes.apply_bcftools_filters = true
    plink2_filters = '--allow-extra-chr 0 --chr 1-22 XY --snps-only --rm-dup exclude-all'  // please do not provide --output-chr chrM  as we need chr prefix not to be present in pipeline for bed and pgen files. Filters to apply to vcf to bed conversion file if genotypes.apply_bcftools_filters = true
    maf = 0.1 // MAF to use in the qtl mapping
    hwe= 0.0000001 // hwe to use in qtl mapping
    windowSize=1000000 // Window around TSS of the gene +-
    numberOfPermutations=1000 // how many permutation to use
    filter_method = 'None' // filterByExpr|HVG|None  // filter genes to test based on these methods.
    norm_method = 'DESEQ'  //'DESEQ|TMM|NONE' // what normalisation method to use for bulk datasets
    percent_of_population_expressed=0.2 // whats the proportion of individuals that has to have the value !=0, Please do not go below 2% as this will result in a lot of low expressed genes which will cause issues in SAIGE and TensorQTL
    tmpdir = "${launchDir}/work" // where to store the temp files.

    dMean_norm_method = 'cp10k' //  'cp10k'|'scT'|'pf_log1p_pf'|'NONE' Normlisation method for dMean, can be cp10k or a precomputed normalised counts layer in the anndata file
    aggregation_columns='Azimuth:predicted.celltype.l1' //for the scrna h5ad file define which annotations to use when aggregating the data. Can be one value or multiple comma separated values
    normalise_before_or_after_aggregation = 'after' // before|after - decission whether to normalise the full dataframe before splitting them in subcategories, or after, i.e normalising per subcategory independently.

    // CONTAINERS
    eqtl_container = 'https://yascp.cog.sanger.ac.uk/public/singularity_images/eqtl_08_07_2024.sif'
    eqtl_docker='mercury/eqtl:08_07_2024'

    saige_container = 'https://yascp.cog.sanger.ac.uk/public/singularity_images/saigeeqtl_0_1_0.sif'
    saige_docker='mercury/saige_eqtl:25_07_2024'
    limix_container='/lustre/scratch123/hgi/mdt1/projects/cardinal_analysis/analysis/mb47/limixJune24.simg'
    
}


process {
    cache = 'lenient'
    maxRetries    = 5
    maxErrors     = '-1'
    errorStrategy = 'retry'
    time   = { 3.h   * task.attempt    }

    withLabel:process_high_memory {
        memory = { 200.GB * task.attempt  }
    }
    withLabel:process_medium_memory {
        memory = { 200.GB * task.attempt }
    }

    withLabel:process_tiny {
      cpus = 1
      maxRetries    = 5
      memory = 2.GB
      time   = {  3.h   * task.attempt }
    }

    withLabel:process_low {
        cpus   = { 1     * task.attempt    }
        memory = { 10.GB * task.attempt }
        time   = { 3.h   * task.attempt   }
    }
    withLabel:process_medium {
        cpus   = { 6     * task.attempt   }
        memory = { 30.GB * task.attempt  }
        time   = { 6.h   * task.attempt    }
    }
    withLabel:process_high {
        cpus   = { 12    * task.attempt    }
        memory = { 20.GB * task.attempt }
        time   = { 16.h  * task.attempt   }
    }

    withLabel:error_ignore {
        errorStrategy = 'ignore'
    }
    withLabel:error_retry {
        errorStrategy = 'retry'
        maxRetries    = 2
    }
    withName: LIMIX{
        errorStrategy = { task.attempt <= 2 ? 'retry' : 'ignore' }
    }    
    withName: SAIGE_S1{
        time   = { 12.h   * task.attempt    }
        maxRetries    = 3
        memory = { 4.GB * task.attempt }
    }
    withName: SAIGE_QVAL_COR{
        time   = { 12.h   * task.attempt    }

    }
    withName: SAIGE_S2{
        time   = { 12.h   * task.attempt    }
        
    }
    withName: DETERMINE_TSS_AND_TEST_REGIONS{
        memory = { 5.GB * task.attempt }
        
    }
    withName: GENOTYPE_PC_CALCULATION{
        cpus  = 1 
        
    }
    withName: SAIGE_S3{
        time   = { 12.h   * task.attempt    }
    }
}

singularity {
    enabled = true
    autoMounts = true
    runOptions = '--nv'
}