/*
========================================================================================
    nf-core/eqtl Nextflow base config file
========================================================================================
    A 'blank slate' config file, appropriate for general use on most high performance
    compute environments. Assumes that all software is installed and available on
    the PATH. Runs in `local` mode - all jobs will be run on the logged in environment.
----------------------------------------------------------------------------------------
*/
params{
    chunkSize=50 // For SAIGE and LIMIX how many genes to chunk at a time to run on a single computation node.
    existing_sparse_grm='' // Do you already have a SPARSE_GRM folder created for these samples in this pipeline? 
    pre_aggregated_counts_folder = '' 
    // Optional. Folder containing subfolders with pre-aggregated phenotype counts and mapping files.
    // Prevents repeated aggregation/normalisation across pipeline runs.
    // Subfolders should follow naming: ___genotype_phenotype_mapping.tsv and ___phenotype_file.tsv

    gtf_gene_identifier = 'gene_id' // Column name in your GTF used as gene identifier (typically 'gene_id' or 'gene_name').

    chromosomes_to_test=[] // Which chromosomes to test? If you set this to '' then it will analyse all available

    //chromosomes_to_test=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,'X','Y'] // !! Important that you plink2_filters and bcftools_filters  bellow align with this especially if you need X then you also need to provide a path to sex info for plink2 conversion
    
    LIMIX{
        run=false // Are we running limix? 
        callRate=0.95 // what call rate to use? 
        blockSize=1500 // What block size to use for mapping?
        hwe=0.0000001 // What hwe to use? 
        numberOfPermutations=10 // how many permutations to use?
    }

    SAIGE{
        run=true // Are we running saige? 
        nr_expression_pcs=5 // How many scRNA expression PCs to use?
        q_val_threshold_for_conditioning=0.05 // If there are >1 genes with q < this, send for conditioning rounds
        minMAF=0.05 // Minimum minor allele frequency to include SNPs
        minMAC=20 // Minimum minor allele count to include SNPs
        SPAcutoff=2 // Cutoff for SPA test (step 2); higher skips fewer SNPs
        markers_per_chunk=10000 // How many markers to test per chunk
        covariate_obs_columns='' // AnnData .obs columns to use as covariates
        cis_trans_mode='cis' // Mode to run: 'cis' or 'trans' associations
        trans_chr_to_test='SAME' // For trans-QTLs, test SAME chromosome as gene or specify one (e.g. '20')

        relatednessCutoff=0.05 // Minimum kinship coefficient for sparse GRM (0.05 ~ 2nd degree relatives)
        numRandomMarkerforSparseKin=1000 // Number of markers to compute sparse GRM
        scale_covariates=true // true|false - should the covariates be scaled using StandardScaler? 
        useSparseGRMtoFitNULL='TRUE' // Use sparse GRM for null model fitting (step 1)
        useSparseGRMforVarRatio='FALSE' // Use sparse GRM to estimate variance ratio (step 1)
        isCateVarianceRatio='TRUE' // Estimate variance ratio per MAC category
        cateVarRatioMinMACVecExclude='0,5' // Lower MAC bin edges to exclude
        cateVarRatioMaxMACVecInclude='4,8' // Upper MAC bin edges to include
        numRandomMarkerforVarianceRatio=1000 // Number of markers to estimate variance ratio

        skipModelFitting='FALSE' // Skip null model fitting if .rda already exists
        skipVarianceRatioEstimation='FALSE' // Skip variance ratio estimation if file already exists

        isCovariateTransform='FALSE' // QR-transform covariates (default TRUE in some setups)
        isCovariateOffset='FALSE' // Include offset term for fixed effect estimation
        isRemoveZerosinPheno='FALSE' // Remove 0s from phenotype values before fitting

        tol=0.00001 // Tolerance for null model convergence
        traceCVcutoff=0.005 // Coefficient of variation threshold for trace estimator
        nrun=15 // Number of runs for trace estimation
        useGRMtoFitNULL='TRUE'
        minMAFforGRM=0.01
        minCovariateCount=-1
        maxMissingRateforGRM=0.15
        LOCO='FALSE'
        maxiterPCG=5000
        invNormalize = 'FALSE'
        step1_extra_flags='' // Extra flags to inject into step1 (fitNULLGLMM)

        existing_phenotype_pcs = "" // default: don't reuse

    }

    TensorQTL{
        run=true // Are we running TensorQTL?
        optimise_pcs = true // Whether to pick the most optimal PCs to use for the downstram analysis. 
        interaction_file='' // to run interaction, provide a TSV with genotype ID and interaction 
        interaction_maf = 0.01 // what interaction MAF to use in tensorqtl interactions test
        interaction_pc_cor_threshold = 0.25 // Drop PCs correlated with interaction above this threshold. Use 1 if you don not want to drop PCs
        interaction_gsea = false // Run GSEA on the interaction terms
        trans_by_cis=true // Run trans-by-cis analysis (all genes, limiting variants) following OPTIM PCs?
        trans_by_cis_variant_list='' // Provide a tsv with variant_id and condition_name OR leave empty to use all lead variants from eGenes
        trans_of_cis=true // Run trans-of-cis eQTL analysis (all variants, limiting genes), following OPTIM PCs?
        trans_by_cis_pval_threshold = 0.01 // when running trans by cis what pval threshold to use.
        alpha=0.05  ///What Alpha value to use in tensorqtl
        chrom_to_map_trans = '' // Option to run GWAS trans analysis - i.e if you specify 2 in here Tensorqtl will run all genes acros genome against all the SNPs on the chromosome 2.
        map_independent_qtls = false
    }

    JAXQTL{
        run=false // Are we running JaxQTL?
        number_of_genes_per_chunk = 250 // How many genes to run at a time for the JaxQTL chunk.
        use_gpu = false // should we use cpus or GPU for the jobs?
    }

    use_sample_pca = true // Set to false if gene PCA is needed
    
    covariates{
        nr_phenotype_pcs = '2,4'
        // Comma-separated list of phenotype PC counts to use per model run.

        nr_genotype_pcs = 4
        // Number of genotype PCs used to account for population structure.

        genotype_pc_filters = '--indep-pairwise 50 5 0.2'
        // PLINK2 flags used when calculating PCs from genotype matrix.

        genotype_pcs_file = ''
        // Optional: Precomputed genotype PCs (TSV; rows = PCs, columns = IIDs).
        // Must include at least `nr_genotype_pcs`.

        extra_covariates_file = ''
        // Optional: Extra covariates for QTL models (numeric only, no missing values).
        // Format:
        //    covariate   S1   S2   S3 ...
        //    Age         35   40   29
        //    BMI         22   27   24
        // First row: sample IDs; first column: covariate names.

        adata_obs_covariate = '' // Optional: Name of a column in the input `.h5ad` `.obs` to include as an extra covariate.
        // Values must be categorical or string; they will be one-hot encoded per sample.
        // Useful for including metadata such as 'Sequencing time', 'Stimulation', or 'Batch'.
    }

    genotypes{
        subset_genotypes_to_available = false
        // If true: filter genotype data to match expression samples (can save memory).

        apply_bcftools_filters = true
        // If true: apply `bcftools_filters` to input VCF before processing.

        use_gt_dosage = true
        // If true: use dosage field (DS) from VCF/PGEN. If false: use GT hard calls.

        preprocessed_bed_file = ''
        // Optional. Path to BED-format PLINK1 dataset (.bed/.bim/.fam)

        preprocessed_pgen_file = ''
        // Preferred. Path to folder with .pgen, .pvar, .psam files (PLINK2).
        // Only one dataset per folder. Avoid mixing datasets inside same dir.

        preprocessed_bgen_file = ''
        // For LIMIX. Must include .bgen, .sample, and .bgi

        hard_call_threshold = 0.499
        geno = 0.01
    }

    outdir='results' // where to output results
    copy_mode = "rellink" // method of processing files in work dir.
    split_aggregation_adata=false  // Should we split the andata per condition before proceeding with the agregations and normalisations
    existing_split_adata_dir='' // Optional: path to directory with pre-split .h5ad files
    genotype_phenotype_mapping_file = '' 
    // TSV with three columns: phenotype_id, genotype_id, Sample_Category.
    // Sample_Category can be used to split the analysis (e.g. for bulk or different stimulations); if not needed, just use a single label for all samples (e.g. "default").
    aggregation_columns='Azimuth:predicted.celltype.l1' //for the scrna h5ad file define which annotations to use when aggregating the data. Can be one value or multiple comma separated values
    aggregation_subentry='' // 'Mono,B,DC' If provided only these subcolumns that are contained within the aggregation_columns entry will be extracted from the merged h5ad file listed in aggregation column
    analysis_subentry='' // after splitting the above dataframe you may want to run a number of celltype\s at a time instead of everything. this will allow you to specify what cells to run.
    gt_id_column = 'Vacutainer ID'
    // Column in the AnnData `.obs` that contains the **donor-level identifier**.
    // This value should match the **genotype ID** in your VCF/PLINK file (e.g. in `.psam`, `.fam`, or `.vcf`),
    // or — if you're using a genotype–phenotype mapping (bridging) file — it should match the `RNA` column in that file.
    // Used to map aggregated expression values to the correct genotype during QTL analysis.

    sample_column = 'pheno_id'
    // Column in the AnnData `.obs` that contains the **sample-level identifier**,
    // representing a single RNA-seq measurement (e.g., one library or sequencing reaction).
    // Used to distinguish multiple samples or runs from the same donor.
    // Can be identical to `gt_id_column` if each sample uniquely maps to one genotype.
    // Combined with `gt_id_column` to generate unique donor-sample IDs for expression aggregation.
    
    utilise_gpu = false // whether to use gpu in tensorqtl or not. 
    gtf_type='gene' //# 'gene|transcript' - if we are using default gtf file as an input we need to know if we are looking at the transcripts of genes. used when gtf file is read to select necessary genes.
    input_tables_column_delimiter = '\t' // by default pipeline takes tsv files but csv could be provided too if this is changed.
    n_min_cells = '5' // The number of min cells for individual to select it for use in qtl mapping. 
    n_min_individ = '30' //Number of individuals that has this particular celltype or aggregation column. Do not select less than 25 since this may result in a permutation issue with tensorqtl
    percent_of_population_expressed=0.2 // whats the proportion of individuals that has to have the value !=0, Please do not go below 2% as this will result in a lot of low expressed genes which will cause issues in SAIGE and TensorQTL
    cell_percentage_threshold = 0 // % of cells that must express the gene
    position = 'TSS' // [ TSS|midpoint ]this can be TSS (for transcriptome, splicing and rna seq experiments) or midpoint (typically for Chi or ATAC qtls)
    aggregation_method = 'dMean,dSum' // can be: dMean|dSum or both dMean,dSum separated by comma
    inverse_normal_transform = 'FALSE' // Inverse normal trasnform data as part of normalisation
    bcftools_filters = '--max-alleles 2 -m2 -M2 -v snps' // Filters to apply to input vcf file if genotypes.apply_bcftools_filters = true
    plink2_filters = '--allow-extra-chr 0 --chr 1-22 X Y XY --snps-only --rm-dup exclude-all'  // please do not provide --output-chr chrM  as we need chr prefix not to be present in pipeline for bed and pgen files. Filters to apply to vcf to bed conversion file if genotypes.apply_bcftools_filters = true
    //# for plink2 filters you also need to provide --update-sex /path/to/sex/info/file/file.txt which contains all the sample info of the sex in tsv format - FID   IID   SEX
    maf = 0.01 // MAF to use in the qtl mapping
    hwe= 0.0000001 // hwe to use in qtl mapping
    windowSize=1000000 // Window around TSS of the gene +-
    numberOfPermutations=1000 // how many permutation to use
    filter_method = 'None' // filterByExpr|HVG|None  // filter genes to test based on these methods.
    norm_method = 'DESEQ'  //'DESEQ|TMM|NONE' // what normalisation method to use for bulk datasets
    tmpdir = "${launchDir}/work" // where to store the temp files.

    dMean_norm_method = 'cp10k' 
    // Normalisation strategy used before `dMean` aggregation in single-cell mode.
    // Options:
    //   - 'cp10k'        : Normalize each cell to 10,000 total counts (UMIs), then log1p transform.
    //   - 'pf_log1p_pf'  : Pseudofactor → log1p → pseudofactor again.
    // If 'NONE', symbolic link is used to copy the original file.

    normalise_before_or_after_aggregation = 'after' // before|after - decission whether to normalise the full h5ad dataframe before splitting them in subcategories, or after, i.e normalising per subcategory independently.

    // CONTAINERS
    eqtl_container = 'https://yascp.cog.sanger.ac.uk/public/singularity_images/eqtl_28_07_2025.sif'
    eqtl_docker='mercury/eqtl:28_07_2025'

    saige_container = 'https://yascp.cog.sanger.ac.uk/public/singularity_images/saigeeqtl_0_1_0.sif'
    saige_docker='mercury/saige_eqtl:10_07_2025'

    saige_grm_container = 'https://yascp.cog.sanger.ac.uk/public/singularity_images/saige_grm_dec2024.sif'
    saige_grm_docker = 'mercury/saige_grm:14_07_2025'
    
    limix_container='https://yascp.cog.sanger.ac.uk/public/singularity_images/limix_2024_25_11.sif'
    limix_docker='mercury/limix_eqtl:25_07_2024'
        
    jax_container='https://yascp.cog.sanger.ac.uk/public/singularity_images/jax_eqtl_22_07_2025.sif'
    jax_docker='mercury/jax_eqtl:22_07_2025'
    
}


process {
    cache = 'lenient'
    maxRetries    = 5
    maxErrors     = '-1'
    errorStrategy = 'retry'
    time   = { 3.h   * task.attempt    }

    withLabel:process_high_memory {
        memory = { 80.GB * task.attempt  }
    }
    withLabel:process_medium_memory {
        memory = { 60.GB * task.attempt }
    }

    withLabel:process_tiny {
      cpus = 1
      maxRetries    = 2
      memory = 1.GB
      time   = {  2.h   * task.attempt }
    }

    withLabel:process_low {
        cpus   = { 1     * task.attempt    }
        memory = { 10.GB * task.attempt }
        time   = { 3.h   * task.attempt   }
    }
    withLabel:process_medium {
        cpus   = { 1     * task.attempt   }
        memory = { 30.GB * task.attempt  }
        time   = { 6.h   * task.attempt    }
    }
    withLabel:process_high {
        cpus   = { 1    * task.attempt    }
        memory = { 20.GB * task.attempt }
        time   = { 16.h  * task.attempt   }
    }

    withLabel:error_ignore {
        errorStrategy = 'ignore'
    }
    withLabel:error_retry {
        errorStrategy = 'retry'
        maxRetries    = 2
    }
    withName: LIMIX{
        errorStrategy = { task.attempt <= 2 ? 'retry' : 'ignore' }
        memory = { 20.GB * task.attempt }
    }    
    withName: SAIGE_S1{
        time   = { 12.h   * task.attempt    }
        maxRetries    = 3
        memory = { 10.GB * task.attempt }
    }
    withName: SAIGE_QVAL_COR{
        time   = { 12.h   * task.attempt    }

    }
    
    withName: JAXQTL {
        memory = 20.GB 
    }

    withLabel: gpu {
        cpus = 1
        maxForks=8
        errorStrategy = 'retry'
        memory = 20.GB 
        time   = { 12.h   * task.attempt }
    }



    withName: PREPROCESS_GENOTYPES{
        memory = { 8.GB * task.attempt }
        cpus  = 1 
        
    }
    withName: GENOTYPE_PC_CALCULATION{
        cpus  = 1 
        memory = { 10.GB * task.attempt }
    }

    withName: AGGREGATE_UMI_COUNTS{
        cpus  = 1 
        
    }
    withName: SAIGE_S2_CIS{
        cpus  = 1 
        memory = { 4.GB * task.attempt }
    }
    
    withName: DETERMINE_TSS_AND_TEST_REGIONS{
        cpus  = 1 
        memory = { 15.GB * task.attempt }
    }
    
    withName: PHENOTYPE_PCs{
        cpus  = 1 
        time   = { 12.h   * task.attempt    }
        memory = { 16.GB * task.attempt } 
    }
    
    withName: SUBSET_PCS{
        cpus  = 1 
        memory = { 2.GB * task.attempt }
        
    }
    withName: NORMALISE_and_PCA_PHENOTYPE{
        cpus  = 1 
        memory = { 10.GB * task.attempt }
    }
    withName: PGEN_CONVERT{
        cpus  = 1 
        memory = { 10.GB * task.attempt }
    }
    withName: PREPERE_EXP_BED{
        cpus  = 1 
        memory = { 15.GB * task.attempt }
    }
    
    withName: CREATE_SPARSE_GRM{
        cpus  = 20 
        memory = { 15.GB * task.attempt }
    }
    
    withName: SAIGE_S3{
        time   = { 12.h   * task.attempt    }
    }    
    withName: AGGREGATE_QTL_ALLVARS{
        time   = { 12.h   * task.attempt    }
        memory = { 15.GB * task.attempt }
    }
    withName:SPLIT_AGGREGATION_ADATA {
        memory = { 64.GB * task.attempt }
    }
}

singularity {
    enabled = true
    autoMounts = true
    runOptions = '--nv'
}
